{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "using: C:/Users/weicheng/Desktop/formal_dataset/p4_x_r1_240813\\4a-240702-gspat-crossing-0.50v-1_001_c_pre_process_df2.csv\n",
      "using: C:/Users/weicheng/Desktop/formal_dataset/p4_x_r1_240813\\4a-240702-gspat-crossing-0.50v-1_002_c_pre_process_df2.csv\n",
      "using: C:/Users/weicheng/Desktop/formal_dataset/p4_x_r1_240813\\4a-240702-gspat-crossing-0.50v-1_003_c_pre_process_df2.csv\n",
      "using: C:/Users/weicheng/Desktop/formal_dataset/p4_x_r1_240813\\4a-240702-gspat-crossing-0.50v-1_004_c_pre_process_df2.csv\n",
      "using: C:/Users/weicheng/Desktop/formal_dataset/p4_x_r1_240813\\4a-240702-gspat-crossing-0.50v-1_005_c_pre_process_df2.csv\n",
      "using: C:/Users/weicheng/Desktop/formal_dataset/p4_x_r1_240813\\4a-240702-gspat-crossing-0.50v-1_006_c_pre_process_df2.csv\n",
      "using: C:/Users/weicheng/Desktop/formal_dataset/p4_x_r1_240813\\4a-240702-gspat-crossing-0.50v-1_007_c_pre_process_df2.csv\n",
      "using: C:/Users/weicheng/Desktop/formal_dataset/p4_x_r1_240813\\4a-240702-gspat-crossing-0.50v-1_008_c_pre_process_df2.csv\n",
      "using: C:/Users/weicheng/Desktop/formal_dataset/p4_x_r1_240813\\4a-240702-gspat-crossing-0.50v-1_009_c_pre_process_df2.csv\n",
      "using: C:/Users/weicheng/Desktop/formal_dataset/p4_x_r1_240813\\4a-240702-gspat-crossing-0.50v-1_010_c_pre_process_df2.csv\n",
      "using: C:/Users/weicheng/Desktop/formal_dataset/p4_x_r1_240813\\4a-240702-gspat-crossing-0.50v-1_011_c_pre_process_df2.csv\n",
      "using: C:/Users/weicheng/Desktop/formal_dataset/p4_x_r1_240813\\4a-240702-gspat-crossing-0.50v-1_013_c_pre_process_df2.csv\n",
      "using: C:/Users/weicheng/Desktop/formal_dataset/p4_x_r1_240813\\4a-240702-gspat-crossing-0.50v-1_014_c_pre_process_df2.csv\n",
      "using: C:/Users/weicheng/Desktop/formal_dataset/p4_x_r1_240813\\4a-240702-gspat-crossing-0.50v-1_015_c_pre_process_df2.csv\n",
      "using: C:/Users/weicheng/Desktop/formal_dataset/p4_x_r1_240813\\4a-240702-gspat-crossing-0.50v-1_016_c_pre_process_df2.csv\n",
      "using: C:/Users/weicheng/Desktop/formal_dataset/p4_x_r1_240813\\4a-240702-gspat-crossing-0.50v-1_017_c_pre_process_df2.csv\n",
      "using: C:/Users/weicheng/Desktop/formal_dataset/p4_x_r1_240813\\4a-240702-gspat-crossing-0.50v-1_018_c_pre_process_df2.csv\n",
      "using: C:/Users/weicheng/Desktop/formal_dataset/p4_x_r1_240813\\4a-240702-gspat-crossing-0.50v-1_019_c_pre_process_df2.csv\n",
      "using: C:/Users/weicheng/Desktop/formal_dataset/p4_x_r1_240813\\4a-240702-gspat-crossing-0.50v-1_021_c_pre_process_df2.csv\n",
      "using: C:/Users/weicheng/Desktop/formal_dataset/p4_x_r1_240813\\4a-240702-gspat-crossing-0.50v-1_022_c_pre_process_df2.csv\n",
      "using: C:/Users/weicheng/Desktop/formal_dataset/p4_x_r1_240813\\4a-240702-gspat-crossing-0.50v-1_c_pre_process_df2.csv\n",
      "WARNING:tensorflow:From c:\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:From c:\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "13/13 [==============================] - 6s 104ms/step - loss: 0.2027 - val_loss: 0.0854\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0624 - val_loss: 0.0479\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0376 - val_loss: 0.0317\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0267 - val_loss: 0.0222\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0218 - val_loss: 0.0181\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0193 - val_loss: 0.0173\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0173 - val_loss: 0.0163\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0159 - val_loss: 0.0155\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0146 - val_loss: 0.0152\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0134 - val_loss: 0.0134\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.0118 - val_loss: 0.0128\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0108 - val_loss: 0.0120\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0098 - val_loss: 0.0119\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0092 - val_loss: 0.0112\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0088 - val_loss: 0.0107\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0082 - val_loss: 0.0101\n",
      "Epoch 17/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0080 - val_loss: 0.0100\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0078 - val_loss: 0.0097\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0074 - val_loss: 0.0090\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0072 - val_loss: 0.0087\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0071 - val_loss: 0.0087\n",
      "Epoch 22/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0068 - val_loss: 0.0085\n",
      "Epoch 23/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0065 - val_loss: 0.0085\n",
      "Epoch 24/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0064 - val_loss: 0.0082\n",
      "Epoch 25/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0061 - val_loss: 0.0080\n",
      "Epoch 26/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0059 - val_loss: 0.0082\n",
      "Epoch 27/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0060 - val_loss: 0.0079\n",
      "Epoch 28/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0060 - val_loss: 0.0082\n",
      "Epoch 29/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0055 - val_loss: 0.0074\n",
      "Epoch 30/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0054 - val_loss: 0.0077\n",
      "Epoch 31/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0054 - val_loss: 0.0072\n",
      "Epoch 32/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0051 - val_loss: 0.0073\n",
      "Epoch 33/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0050 - val_loss: 0.0078\n",
      "Epoch 34/100\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.0050 - val_loss: 0.0078\n",
      "Epoch 35/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0049 - val_loss: 0.0072\n",
      "Epoch 36/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0048 - val_loss: 0.0072\n",
      "Epoch 37/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0046 - val_loss: 0.0071\n",
      "Epoch 38/100\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0047 - val_loss: 0.0068\n",
      "Epoch 39/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0045 - val_loss: 0.0068\n",
      "Epoch 40/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0044 - val_loss: 0.0069\n",
      "Epoch 41/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0042 - val_loss: 0.0066\n",
      "Epoch 42/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0041 - val_loss: 0.0066\n",
      "Epoch 43/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0041 - val_loss: 0.0070\n",
      "Epoch 44/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0043 - val_loss: 0.0068\n",
      "Epoch 45/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0039 - val_loss: 0.0064\n",
      "Epoch 46/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0039 - val_loss: 0.0064\n",
      "Epoch 47/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0040 - val_loss: 0.0064\n",
      "Epoch 48/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0039 - val_loss: 0.0063\n",
      "Epoch 49/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0037 - val_loss: 0.0062\n",
      "Epoch 50/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0037 - val_loss: 0.0069\n",
      "Epoch 51/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0036 - val_loss: 0.0068\n",
      "Epoch 52/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0035 - val_loss: 0.0062\n",
      "Epoch 53/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0035 - val_loss: 0.0064\n",
      "Epoch 54/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0034 - val_loss: 0.0062\n",
      "Epoch 55/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0036 - val_loss: 0.0063\n",
      "Epoch 56/100\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.0034 - val_loss: 0.0062\n",
      "Epoch 57/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0034 - val_loss: 0.0061\n",
      "Epoch 58/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0033 - val_loss: 0.0063\n",
      "Epoch 59/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0033 - val_loss: 0.0063\n",
      "Epoch 60/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0033 - val_loss: 0.0066\n",
      "Epoch 61/100\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0032 - val_loss: 0.0060\n",
      "Epoch 62/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0031 - val_loss: 0.0062\n",
      "Epoch 63/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0033 - val_loss: 0.0065\n",
      "Epoch 64/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0032 - val_loss: 0.0065\n",
      "Epoch 65/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0030 - val_loss: 0.0064\n",
      "Epoch 66/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0030 - val_loss: 0.0061\n",
      "Epoch 67/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0030 - val_loss: 0.0063\n",
      "Epoch 68/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0032 - val_loss: 0.0064\n",
      "Epoch 69/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0031 - val_loss: 0.0059\n",
      "Epoch 70/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0030 - val_loss: 0.0067\n",
      "Epoch 71/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0030 - val_loss: 0.0060\n",
      "Epoch 72/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0030 - val_loss: 0.0061\n",
      "Epoch 73/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0029 - val_loss: 0.0061\n",
      "Epoch 74/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0028 - val_loss: 0.0062\n",
      "Epoch 75/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0028 - val_loss: 0.0062\n",
      "Epoch 76/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0028 - val_loss: 0.0063\n",
      "Epoch 77/100\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.0028 - val_loss: 0.0060\n",
      "Epoch 78/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0028 - val_loss: 0.0062\n",
      "Epoch 79/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0028 - val_loss: 0.0062\n",
      "Epoch 80/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0027 - val_loss: 0.0061\n",
      "Epoch 81/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0029 - val_loss: 0.0068\n",
      "Epoch 82/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0030 - val_loss: 0.0064\n",
      "Epoch 83/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0027 - val_loss: 0.0064\n",
      "Epoch 84/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0026 - val_loss: 0.0062\n",
      "Epoch 85/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0028 - val_loss: 0.0060\n",
      "Epoch 86/100\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0028 - val_loss: 0.0060\n",
      "Epoch 87/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0027 - val_loss: 0.0061\n",
      "Epoch 88/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0026 - val_loss: 0.0064\n",
      "Epoch 89/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0027 - val_loss: 0.0059\n",
      "Epoch 90/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0026 - val_loss: 0.0060\n",
      "Epoch 91/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0026 - val_loss: 0.0059\n",
      "Epoch 92/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0025 - val_loss: 0.0063\n",
      "Epoch 93/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0026 - val_loss: 0.0063\n",
      "Epoch 94/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0027 - val_loss: 0.0061\n",
      "Epoch 95/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0026 - val_loss: 0.0060\n",
      "Epoch 96/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0025 - val_loss: 0.0065\n",
      "Epoch 97/100\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.0026 - val_loss: 0.0064\n",
      "Epoch 98/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0024 - val_loss: 0.0061\n",
      "Epoch 99/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0025 - val_loss: 0.0063\n",
      "Epoch 100/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0024 - val_loss: 0.0060\n",
      "4/4 [==============================] - 1s 3ms/step\n",
      "[[ 1.02328633e-01 -2.24594876e-02 -3.47292078e-02 ...  4.57176084e-03\n",
      "  -7.96019128e-03  1.27795750e-01]\n",
      " [ 1.08376880e-01 -2.02633625e-02 -3.55248112e-02 ...  2.09407269e-03\n",
      "  -5.68108269e-03  1.27657104e-01]\n",
      " [ 1.16701382e-01 -1.80767952e-02 -3.71000711e-02 ...  6.46150599e-05\n",
      "  -3.42003291e-03  1.27578830e-01]\n",
      " ...\n",
      " [ 4.23276894e-01  3.78111135e-02  2.14810227e-02 ... -4.84666899e-02\n",
      "   4.57062774e-02  1.22951533e-01]\n",
      " [ 4.26438932e-01  3.90078006e-02  2.39932024e-02 ... -4.88047816e-02\n",
      "   4.47408565e-02  1.22951266e-01]\n",
      " [ 4.31274641e-01  4.03348301e-02  2.48533593e-02 ... -4.68855667e-02\n",
      "   4.25334939e-02  1.23097244e-01]]\n",
      "122\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "import glob\n",
    "\n",
    "# Load your dataset\n",
    "# Assume the dataset is a CSV file with columns: 'x', 'y', 'z', 'amplitude', 'phase'\n",
    "# data = pd.read_csv('particle_data.csv')\n",
    "\n",
    "\n",
    "# Load your dataset\n",
    "# data = pd.read_csv(r\"C:\\Users\\weicheng\\Desktop\\formal_dataset\\p4_stacking_r1\\4a-240702-gspat-stacking-0.01v-1_001_pre_process_df2.csv\")\n",
    "# data_label = pd.read_csv(r\"C:\\Users\\weicheng\\Desktop\\formal_dataset\\p4_stacking_r1\\4a-240702-gspat-stacking-0.01v-1_001_pre_process_df_labels.csv\")\n",
    "\n",
    "# # Concatenate both datasets if they have the same structure\n",
    "# data_combined = pd.concat([data, data_label], axis=1)\n",
    "\n",
    "# # Drop rows with any NaN values from combined dataset\n",
    "# data_combined.dropna(axis=0, how='any', inplace=True)\n",
    "\n",
    "\n",
    "# Preprocess the data\n",
    "features = ['time', 'x0', 'y0', 'z0', 'x1', 'y1', 'z1', 'x2', 'y2', 'z2', 'x3', 'y3', 'z3', 'amp0', 'phase0', 'amp1', 'phase1', 'amp2', 'phase2', 'amp3', 'phase3']\n",
    "# target = ['x1', 'y1', 'z1']\n",
    "\n",
    "# Load all CSV files\n",
    "file_pattern = 'C:/Users/weicheng/Desktop/formal_dataset/p4_x_r1_240813/4a-240702-gspat-crossing-0.50v-1*_pre_process_df2.csv'  # Adjust the pattern to match your files\n",
    "files = glob.glob(file_pattern)\n",
    "# files = []\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# Function to preprocess and create sequences\n",
    "def preprocess_and_create_sequences(file, time_steps=10):\n",
    "    print(\"using:\", file)\n",
    "    data = pd.read_csv(file)\n",
    "\n",
    "    # # Interpolate NaNs using spline method\n",
    "    # data = data.interpolate(method='spline', order=3)\n",
    "    \n",
    "    # # Fill any remaining NaNs if interpolation did not cover some edge cases\n",
    "    # data = data.fillna(method='bfill').fillna(method='ffill')\n",
    "\n",
    "    data.dropna(axis=0, how='any', inplace=True)\n",
    "    # print(data)\n",
    "\n",
    "    scaled_data = scaler.fit_transform(data[features])\n",
    "    X, y = create_dataset(scaled_data, time_steps)\n",
    "    return X, y\n",
    "\n",
    "# Convert the data to a supervised learning problem\n",
    "def create_dataset(data, time_steps=1):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - time_steps):\n",
    "        X.append(data[i:(i + time_steps), :])\n",
    "        y.append(data[i + time_steps, 0:13])  # Predicting x, y, z\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Define the number of time steps\n",
    "time_steps = 10\n",
    "\n",
    "# Create a list to store training and testing datasets\n",
    "X_train_list, y_train_list = [], []\n",
    "X_test_list, y_test_list = [], []\n",
    "\n",
    "# Split files into training and testing sets (80% training, 20% testing)\n",
    "train_files = files[:int(len(files) * 0.8)]\n",
    "test_files = files[int(len(files) * 0.8):]\n",
    "\n",
    "# Process each training file\n",
    "for file in train_files:\n",
    "    X, y = preprocess_and_create_sequences(file, time_steps)\n",
    "    X_train_list.append(X)\n",
    "    y_train_list.append(y)\n",
    "\n",
    "# Process each testing file\n",
    "for file in test_files:\n",
    "    X, y = preprocess_and_create_sequences(file, time_steps)\n",
    "    X_test_list.append(X)\n",
    "    y_test_list.append(y)\n",
    "\n",
    "# Concatenate all training and testing data\n",
    "X_train = np.concatenate(X_train_list, axis=0)\n",
    "y_train = np.concatenate(y_train_list, axis=0)\n",
    "X_test = np.concatenate(X_test_list, axis=0)\n",
    "y_test = np.concatenate(y_test_list, axis=0)\n",
    "\n",
    "# Build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, return_sequences=True, input_shape=(time_steps, len(features))))\n",
    "model.add(LSTM(50))\n",
    "model.add(Dense(13))  # Output layer predicting x, y, z\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Inverse transform the predictions to the original scale\n",
    "scaled_predictions = np.concatenate((predictions, np.zeros((predictions.shape[0], len(features) - 13))), axis=1)\n",
    "predictions = scaler.inverse_transform(scaled_predictions)[:, 0:13]\n",
    "\n",
    "# Print the first 5 predictions\n",
    "print(predictions)\n",
    "print(len(predictions))\n",
    "\n",
    "# Round the first column to 2 decimal places\n",
    "predictions[:, 0] = np.round(predictions[:, 0], 2)\n",
    "\n",
    "# Save predictions to CSV\n",
    "output_df = pd.DataFrame(predictions, columns=['time', 'x0', 'y0', 'z0', 'x1', 'y1', 'z1', 'x2', 'y2' ,'z2', 'x3', 'y3' ,'z3'])\n",
    "output_df.to_csv('predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
